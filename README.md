Conjunto de Repositorios Spark

Este repositorio contiene una serie de subrepositorios que abarcan diferentes entornos y configuraciones para trabajar con Apache Spark. Cada uno de estos subrepositorios está diseñado para cubrir una parte específica del ecosistema Spark, desde instalaciones locales hasta la integración en plataformas en la nube. A continuación, se describe cada subrepositorio en detalle:

Descripción de los Subrepositorios

01-Instalacion-Spark
https://github.com/Mikemaranon/linux-cosas

Este subrepositorio contiene scripts y documentación para la instalación de Apache Spark de manera local. Incluye instrucciones detalladas para configurar Spark en un entorno Linux y comenzar a utilizar herramientas como Spark Shell, PySpark y Spark SQL. Es ideal para aquellos que deseen aprender a instalar y ejecutar Spark en sus propios sistemas.

02-Docker-Spark
https://github.com/Viku365/docker-spark-jupyter

Este subrepositorio incluye archivos Docker y configuraciones para crear un entorno Spark utilizando contenedores Docker. Proporciona un entorno portátil y fácil de gestionar, sin necesidad de realizar instalaciones permanentes en la máquina local. Es especialmente útil para quienes prefieren trabajar con Spark de una manera más flexible y reproducible.

03-Azure-MV-SPARK
https://github.com/SergioFerrerasRuiz/Practica11_MV_AZURE_SPARK

En este subrepositorio se documenta la instalación y configuración de Spark en una Máquina Virtual (MV) de Azure. Proporciona instrucciones sobre cómo crear una máquina virtual, instalar Spark y configurarla para su uso en entornos de desarrollo, pruebas o producción en la nube. Es una excelente opción para quienes buscan implementar Spark en un entorno controlado y escalable en Azure.

04-Azure-Databricks
https://github.com/carlosalonso99-tajamar/azure-databricks-etl-enviroment

Este subrepositorio está enfocado en la configuración y uso de Azure Databricks, un servicio en la nube basado en Apache Spark. Incluye ejemplos prácticos sobre cómo crear clusters, cargar datos y trabajar con notebooks en Databricks. Azure Databricks facilita la colaboración y el desarrollo de soluciones de Big Data y machine learning de manera eficiente.

05-AzureSynapseAnalytics-Spark
https://github.com/Viku365/AzureSynapseAnalytics

En este subrepositorio se describe cómo utilizar Spark dentro de Azure Synapse Analytics. Azure Synapse integra Spark para análisis de datos, ofreciendo un entorno unificado que permite combinar el análisis de Big Data con herramientas de machine learning. Es ideal para proyectos que requieren un enfoque integral de procesamiento y análisis de datos.

06-AzureHDInsight-Spark
https://github.com/alejandrorod-tajamar/Spark-AzureHDInsight

Este subrepositorio proporciona una guía detallada para configurar y utilizar Spark en Azure HDInsight. HDInsight es un servicio que facilita la creación y gestión de clusters Spark, permitiendo el procesamiento distribuido de grandes volúmenes de datos de forma sencilla. Este subrepositorio es útil para quienes buscan aprovechar la infraestructura de Azure para gestionar datos a gran escala.

07-Databricks+Google-Collab
https://github.com/MarioSantanaTajamar/Databricks_Google-Collab

Este subrepositorio combina el uso de Azure Databricks con Google Colab, proporcionando una forma sencilla de experimentar con Apache Spark. Incluye instrucciones sobre cómo integrar ambos entornos, aprovechando la flexibilidad de Google Colab para compartir y ejecutar notebooks, mientras se utiliza la potencia de Databricks para el procesamiento de datos. Es ideal para la experimentación y el aprendizaje colaborativo.
